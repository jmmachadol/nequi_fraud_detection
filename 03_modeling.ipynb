{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fabf782d",
   "metadata": {},
   "source": [
    "# 03 · Modelado de anomalías\n",
    "\n",
    "**Objetivo.**  \n",
    "Entrenar un modelo no-supervisado (Isolation Forest) para detectar transacciones atípicas, medir `precision@k` y guardar los artefactos (modelo, escalador, ranking de scores).\n",
    "\n",
    "> Decisiones implementadas  \n",
    "> * Eliminar `tx_sum_6h` y `ratio_cnt_1h_24h` (correlación > 0.95).  \n",
    "> * Imputar todos los `NaN` con **0**.  \n",
    "> * `contamination` = **1 %** (≈ 107 k registros marcados como outlier).  \n",
    "> * Métricas: `precision@k` para k = 100, 500, 0.1 % (≈ 10 758).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:43:39 | INFO | df_features cargado: 10,758,402 filas  |  29 columnas\n"
     ]
    }
   ],
   "source": [
    "# D.0 · Setup y carga\n",
    "import time, joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from src.utils import log_step\n",
    "\n",
    "# Rutas\n",
    "CACHE_DIR = Path(\"./cache\")\n",
    "ARTIFACTS = Path(\"./artifacts\")\n",
    "ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.read_parquet(CACHE_DIR / \"df_features.parquet\")\n",
    "log_step(f\"df_features cargado: {len(df):,} filas  |  {df.shape[1]} columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56935a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D.1 · build_X() – imputación 0 + escalado opcional\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def build_X(df: pd.DataFrame, scale: bool = False, drop_cols=None):\n",
    "    \"\"\"Devuelve matriz de features lista para el modelo.\"\"\"\n",
    "    if drop_cols is None:\n",
    "        drop_cols = []\n",
    "    X = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    num_cols = X.select_dtypes(include=[\"number\", \"Int32\", \"float32\", \"float64\"]).columns\n",
    "    X = X[num_cols]\n",
    "\n",
    "    steps = [(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=0))]\n",
    "    if scale:\n",
    "        steps.append((\"scaler\", StandardScaler()))\n",
    "    pipe = Pipeline(steps)\n",
    "    X_proc = pipe.fit_transform(X)\n",
    "    return X_proc, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01418f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:02:01 | INFO | [IF-100] Entrenado en 884.3s\n"
     ]
    }
   ],
   "source": [
    "# D.2 · Isolation Forest \n",
    "DROP_COLS = [\"tx_sum_6h\", \"ratio_cnt_1h_24h\"]\n",
    "X_if, pipe_pre_if = build_X(df, scale=False, drop_cols=DROP_COLS)\n",
    "\n",
    "model_if = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples=0.6,\n",
    "    contamination=0.01,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "t0 = time.time()\n",
    "model_if.fit(X_if)\n",
    "log_step(f\"[IF-100] Entrenado en {time.time()-t0:.1f}s\")\n",
    "\n",
    "scores_if = -model_if.score_samples(X_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f600b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:07:14 | INFO | [IF-100] Top-   100: threshold = 0.719\n",
      "2025-06-30 13:07:14 | INFO | [IF-100] Top-   500: threshold = 0.677\n",
      "2025-06-30 13:07:14 | INFO | [IF-100] Top- 10758: threshold = 0.590\n"
     ]
    }
   ],
   "source": [
    "# D.3 · Funciones comunes: ranking + precision@k\n",
    "def topk_threshold(scores, k):\n",
    "    \"\"\"Devuelve el umbral que deja exactamente k observaciones por encima.\"\"\"\n",
    "    return np.partition(scores, -k)[-k]\n",
    "\n",
    "def precision_at_k(scores, k):\n",
    "    # sin etiquetas reales la precisión nominal es 1 (marcamos exactamente k)\n",
    "    return 1.0\n",
    "\n",
    "K_LIST = [100, 500, int(0.001*len(scores_if))]\n",
    "for k in K_LIST:\n",
    "    thr = topk_threshold(scores_if, k)\n",
    "    log_step(f\"[IF-100] Top-{k:>6}: threshold = {thr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:11:41 | INFO | [PCA-10] Ajustada en 2.1s\n",
      "2025-06-30 13:12:04 | INFO | [PCA-10] Error de reconstr. calculado en 23.4s |  filas: 10,758,402\n",
      "2025-06-30 13:12:04 | INFO | [PCA-10] Top-   100: threshold = 26.492\n",
      "2025-06-30 13:12:04 | INFO | [PCA-10] Top-   500: threshold = 18.317\n",
      "2025-06-30 13:12:04 | INFO | [PCA-10] Top- 10758: threshold = 4.956\n"
     ]
    }
   ],
   "source": [
    "# D.4 · Error de reconstrucción con PCA-10 (autosuficiente)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 1) Matriz numérica X completa (imputación + escalado)\n",
    "X_full, pre_pca = build_X(df, scale=True, drop_cols=DROP_COLS)\n",
    "\n",
    "# 2) Ajuste PCA a 10 componentes\n",
    "t0 = time.time()\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "X_full_pca = pca.fit_transform(X_full)\n",
    "log_step(f\"[PCA-10] Ajustada en {time.time()-t0:.1f}s\")\n",
    "\n",
    "# 3) Reconstrucción y cálculo de MSE por fila\n",
    "t0 = time.time()\n",
    "X_recon = pca.inverse_transform(X_full_pca)\n",
    "squared_err = np.square(X_full - X_recon).mean(axis=1).astype(\"float32\")\n",
    "scores_pca = squared_err           # mayor = más anómalo\n",
    "log_step(f\"[PCA-10] Error de reconstr. calculado en {time.time()-t0:.1f}s \"\n",
    "         f\"|  filas: {len(scores_pca):,}\")\n",
    "\n",
    "# 4) Thresholds para los k solicitados\n",
    "for k in K_LIST:\n",
    "    thr = topk_threshold(scores_pca, k)\n",
    "    log_step(f\"[PCA-10] Top-{k:>6}: threshold = {thr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaede5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thr@100</th>\n",
       "      <th>prec@100</th>\n",
       "      <th>thr@500</th>\n",
       "      <th>prec@500</th>\n",
       "      <th>thr@10758</th>\n",
       "      <th>prec@10758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IF-100</th>\n",
       "      <td>0.7190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6769</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA-10</th>\n",
       "      <td>26.4917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.3166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        thr@100  prec@100  thr@500  prec@500  thr@10758  prec@10758\n",
       "IF-100   0.7190       1.0   0.6769       1.0     0.5902         1.0\n",
       "PCA-10  26.4917       1.0  18.3166       1.0     4.9558         1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:12:06 | INFO | Tabla de métricas generada\n"
     ]
    }
   ],
   "source": [
    "# D.5 · Tabla comparativa de métricas (IF-100 y PCA-10)\n",
    "\n",
    "def build_metrics_dict(name: str, scores) -> pd.Series:\n",
    "    \"\"\"Calcula threshold y precision@k (siempre 1) para cada k.\"\"\"\n",
    "    data = {}\n",
    "    for k in K_LIST:\n",
    "        data[f\"thr@{k}\"]  = float(topk_threshold(scores, k))\n",
    "        data[f\"prec@{k}\"] = 1.0           # por construcción\n",
    "    return pd.Series(data, name=name)\n",
    "\n",
    "df_metrics = pd.concat([\n",
    "    build_metrics_dict(\"IF-100\",  scores_if),\n",
    "    build_metrics_dict(\"PCA-10\",  scores_pca),\n",
    "], axis=1).T\n",
    "\n",
    "df_metrics_rounded = df_metrics.round(4)\n",
    "display(df_metrics_rounded)\n",
    "\n",
    "log_step(\"Tabla de métricas generada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a99ea",
   "metadata": {},
   "source": [
    "> Nota: los umbrales de IF-100 (basados en profundidad de aislamiento) y\n",
    "los de PCA-10 (error cuadrático medio) no son comparables en valor\n",
    "absoluto; sólo el ranking determina las alertas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd067e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:17:22 | INFO | Artefactos y ranking guardados en /artifacts\n"
     ]
    }
   ],
   "source": [
    "# D.6 · Persistencia de modelos y rankings finales\n",
    "\n",
    "ARTIFACTS = Path(\"./artifacts\")\n",
    "ARTIFACTS.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- Isolation Forest -----------------------------------\n",
    "joblib.dump(\n",
    "    {\"pre\": pipe_pre_if, \"model\": model_if},\n",
    "    ARTIFACTS / \"if100.joblib\",\n",
    "    compress=3,\n",
    ")\n",
    "\n",
    "# ---------- Preprocesador + PCA(10) ----------------------------\n",
    "# build_X nos devuelve el pipeline (imputer + scaler) coherente\n",
    "_, pre_pca = build_X(df, scale=True, drop_cols=DROP_COLS)\n",
    "joblib.dump(\n",
    "    {\"pre\": pre_pca, \"model\": pca},\n",
    "    ARTIFACTS / \"pca10.joblib\",\n",
    "    compress=3,\n",
    ")\n",
    "\n",
    "# ---------- Ranking Top-N de Isolation Forest ------------------\n",
    "TOP_N = 10_000\n",
    "ranking_if = (\n",
    "    df.assign(anomaly_score=scores_if)\n",
    "      .nlargest(TOP_N, \"anomaly_score\")\n",
    "      .loc[:, [\"_id\", \"user_id\", \"transaction_date\",\n",
    "               \"transaction_amount\", \"transaction_type\",\n",
    "               \"anomaly_score\"]]\n",
    ")\n",
    "\n",
    "ranking_if.to_parquet(\n",
    "    ARTIFACTS / \"scores_if100.parquet\",\n",
    "    compression=\"snappy\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "log_step(\"Artefactos y ranking guardados en /artifacts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73548ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 13:17:27 | INFO | Nuevo umbral para rate=0.500%: 0.534 |  outliers: 53,792\n",
      "2025-06-30 13:17:31 | INFO | Nuevo umbral para rate=0.300%: 2.694 |  outliers: 32,275\n"
     ]
    }
   ],
   "source": [
    "# D.7 · Función opcional: recalcular umbral a otro contamination\n",
    "def recompute_threshold(scores_array, new_rate=0.005):\n",
    "    \"\"\"\n",
    "    Calcula el nuevo umbral que deja 'new_rate' de observaciones\n",
    "    como outliers (scores más altos).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores_array : 1-D np.ndarray\n",
    "        Vector de scores (mayor = más anómalo).\n",
    "    new_rate : float, default 0.005\n",
    "        Porción deseada de outliers (entre 0 y 1).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    thr : float\n",
    "        Nuevo umbral.\n",
    "    top_idx : np.ndarray\n",
    "        Índices de las observaciones consideradas outliers (ordenadas).\n",
    "    \"\"\"\n",
    "    n = len(scores_array)\n",
    "    k_new = max(1, int(new_rate * n))   # asegura k ≥ 1\n",
    "    thr = topk_threshold(scores_array, k_new)\n",
    "    \n",
    "    # Índices de los top-k (ordenados, utilidad práctica)\n",
    "    top_idx = np.argsort(scores_array)[-k_new:]\n",
    "    \n",
    "    log_step(f\"Nuevo umbral para rate={new_rate:.3%}: {thr:.3f} \"\n",
    "             f\"|  outliers: {k_new:,}\")\n",
    "    return thr, top_idx\n",
    "\n",
    "# Ejemplo de uso con Isolation Forest\n",
    "thr_if, idx_if = recompute_threshold(scores_if, new_rate=0.005)\n",
    "\n",
    "# Ejemplo opcional con PCA-error\n",
    "thr_pca, idx_pca = recompute_threshold(scores_pca, new_rate=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcfab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_pca = (\n",
    "    df.assign(anomaly_score=scores_pca)\n",
    "      .nlargest(TOP_N, \"anomaly_score\")\n",
    ")\n",
    "ranking_pca.to_parquet(ARTIFACTS / \"scores_pca10.parquet\",\n",
    "                       compression=\"snappy\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab3d7c",
   "metadata": {},
   "source": [
    "## Conclusiones del modelado & decisiones de selección de modelos  \n",
    "\n",
    "**Resumen de desempeño (Top-k thresholds)**  \n",
    "\n",
    "| Modelo | thr@100 | thr@500 | thr@0.1 % (10 758) |\n",
    "|--------|--------:|--------:|-------------------:|\n",
    "| **Isolation Forest (IF-100)** | 0.7190 | 0.6769 | 0.5902 |\n",
    "| **PCA-10 (error de reconstrucción)** | 26.492 | 18.316 | 4.9558 |\n",
    "\n",
    "\n",
    "> Los umbrales no son comparables en valor absoluto—cada algoritmo produce scores en escalas distintas.  \n",
    "> La comparación se basa en el **ranking**: un `thr@k` define qué tan profundo entra el modelo para marcar el mismo número de alertas.\n",
    "\n",
    "---\n",
    "\n",
    "### Justificación de los modelos  \n",
    "\n",
    "| Algoritmo | Justificación |\n",
    "|-----------|-----------------------------------------|\n",
    "| **IF-100** | Escalable a 10.7 M filas; umbrales estables; interpretabilidad directa con SHAP-Tree. |\n",
    "| **PCA-10** | Complementa con detección de anomalías lineales globales; coste de cómputo bajo. |\n",
    "\n",
    "---\n",
    "\n",
    "### Umbral operativo ajustable  \n",
    "\n",
    "La función `recompute_threshold(scores_array, new_rate)` permite recalibrar la tasa de alertas sin re-entrenar el modelo.  \n",
    "Ejemplo de uso sobre IF-100:\n",
    "\n",
    "```python\n",
    "thr_if_05, idx_if_05 = recompute_threshold(scores_if, new_rate=0.005)  # 0.5 %\n",
    "```\n",
    "\n",
    "Esto genera un nuevo umbral (`thr_if_05 ≈ 0.534`) y la lista de índices (`idx_if_05`) correspondiente a ~0.5 % de transacciones con mayor score.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
